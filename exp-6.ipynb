{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27edde69-d5c9-4235-b440-fcc7e1e96f9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the topic to search news for:  ai\n",
      "Do you want to restrict to specific websites? (y/n):  y\n",
      "Enter websites separated by comma (e.g., bbc.com,reuters.com):  bbc.com\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " News Stories Found:\n",
      "\n",
      "1. Artificial intelligence - BBC News\n",
      "   https://www.bbc.com/news/topics/ce1qrvleleqt\n",
      "   üìù All the latest content about Artificial intelligence from the BBC.\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from googlesearch import search\n",
    "\n",
    "def fetch_news(topic, limit_websites=None, num_results=10):\n",
    "    \"\"\"\n",
    "    Fetch news stories about a topic.\n",
    "    \n",
    "    :param topic: (str) Topic to search for\n",
    "    :param limit_websites: (list) List of websites to restrict crawling to (optional)\n",
    "    :param num_results: (int) Number of search results to fetch\n",
    "    :return: (list) News headlines and links\n",
    "    \"\"\"\n",
    "    query = topic + \" news\"\n",
    "    results = []\n",
    "\n",
    "    # Google Search\n",
    "    for url in search(query, num_results=num_results):\n",
    "        # If website restriction is set, check domain\n",
    "        if limit_websites:\n",
    "            if not any(site in url for site in limit_websites):\n",
    "                continue  # skip if not in allowed sites\n",
    "\n",
    "        try:\n",
    "            response = requests.get(url, timeout=5)\n",
    "            soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "            # Extract title\n",
    "            title = soup.find(\"title\").get_text() if soup.find(\"title\") else \"No Title\"\n",
    "            \n",
    "            # Extract meta description if available\n",
    "            description = \"\"\n",
    "            meta = soup.find(\"meta\", attrs={\"name\": \"description\"})\n",
    "            if meta:\n",
    "                description = meta.get(\"content\", \"\")\n",
    "\n",
    "            results.append({\"title\": title, \"url\": url, \"description\": description})\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to fetch {url}: {e}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "# ----------------- RUN PROGRAM -----------------\n",
    "if __name__ == \"__main__\":\n",
    "    topic = input(\"Enter the topic to search news for: \")\n",
    "    choice = input(\"Do you want to restrict to specific websites? (y/n): \").lower()\n",
    "\n",
    "    websites = None\n",
    "    if choice == \"y\":\n",
    "        websites = input(\"Enter websites separated by comma (e.g., bbc.com,reuters.com): \").split(\",\")\n",
    "\n",
    "    news_list = fetch_news(topic, limit_websites=websites, num_results=15)\n",
    "\n",
    "    print(\"\\n News Stories Found:\\n\")\n",
    "    for i, news in enumerate(news_list, 1):\n",
    "        print(f\"{i}. {news['title']}\")\n",
    "        print(f\"   {news['url']}\")\n",
    "        if news['description']:\n",
    "            print(f\"   üìù {news['description']}\")\n",
    "        print(\"-\" * 80)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
